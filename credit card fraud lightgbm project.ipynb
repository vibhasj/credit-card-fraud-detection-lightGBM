{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPC4kf3AN9GP"
   },
   "source": [
    "##DATA INGESTION\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30685,
     "status": "ok",
     "timestamp": 1765522705104,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "bppGX2OcOAjz",
    "outputId": "f539fb7c-4491-4909-b234-59f063ca9cb9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your local file\n",
    "DATA_PATH = r\"C:\\Users\\vibhas\\Downloads\\creditcard.csv\"\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1961,
     "status": "ok",
     "timestamp": 1765522708929,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "CSiz3bCEO-DY",
    "outputId": "9cfca3bc-7619-41f0-f0d0-e41831a70f8e"
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "#missing and duplicated values\n",
    "print(df[df.duplicated(keep=False)])\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt_PcLIrSyBL"
   },
   "source": [
    "##Train,Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1765522720426,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "P8PvKs4OS3YD",
    "outputId": "6c7a50c0-6264-415b-da57-3f40b3cba324"
   },
   "outputs": [],
   "source": [
    "# TRAIN/VAL/TEST SPLIT (70/15/15) WITH STRATIFICATION\n",
    "# Separate features and target\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "# First split: 70% train, 30% temp (which will become val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: Split the 30% into 15% val and 15% test (50/50 split of temp)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Verify splits\n",
    "print(\"DATASET SPLIT SUMMARY\")\n",
    "print(f\"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Val set:   {X_val.shape[0]} samples ({X_val.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nTotal: {X_train.shape[0] + X_val.shape[0] + X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IEh896WUjZ-"
   },
   "source": [
    "##IMBALANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1765522724970,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "pgA_RJRDVLbh",
    "outputId": "66997f92-4f8f-43bc-d638-d257f5f6a8f2"
   },
   "outputs": [],
   "source": [
    "# CLASS IMBALANCE ANALYSIS\n",
    "\n",
    "print(\"IMBALANCE CLASS DISTRIBUTION\")\n",
    "\n",
    "for split_name, y_split in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "    fraud_count = y_split.sum()\n",
    "    normal_count = len(y_split) - fraud_count\n",
    "    total_count = len(y_split)\n",
    "\n",
    "    fraud_pct = (fraud_count / total_count) * 100\n",
    "    normal_pct = (normal_count / total_count) * 100\n",
    "\n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Normal: {normal_count:6} ({normal_pct:6.2f}%)\")\n",
    "    print(f\"  Fraud:  {fraud_count:6} ({fraud_pct:6.4f}%)\")\n",
    "    print(f\"  Ratio:  {fraud_count}/{total_count} (approx 1 fraud per {int(total_count/fraud_count)} transactions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJrS89iYcnZb"
   },
   "source": [
    "##feature eng and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1765522729521,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "Q3VbacSMcrHZ",
    "outputId": "b87f6b98-dea7-401e-cf6d-2cb4ad63fb9c"
   },
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "SCALER_PATH = 'models/robust_scaler.joblib'\n",
    "SCALING_FEATURES = ['Time', 'Amount']\n",
    "\n",
    "# Create copies of the feature sets to avoid setting on slice warnings\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 2.1: Apply RobustScaler (Fit only on Train)\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"--- Phase 2: Feature Scaling and Saving ---\")\n",
    "print(f\"Applying RobustScaler to: {SCALING_FEATURES}\")\n",
    "\n",
    "# Initialize the RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# 1. FIT the scaler ONLY on the Training data\n",
    "print(\"1. Fitting RobustScaler on X_train...\")\n",
    "scaler.fit(X_train_scaled[SCALING_FEATURES])\n",
    "\n",
    "# 2. TRANSFORM all three sets using the parameters learned from X_train\n",
    "X_train_scaled[SCALING_FEATURES] = scaler.transform(X_train_scaled[SCALING_FEATURES])\n",
    "X_val_scaled[SCALING_FEATURES] = scaler.transform(X_val_scaled[SCALING_FEATURES])\n",
    "X_test_scaled[SCALING_FEATURES] = scaler.transform(X_test_scaled[SCALING_FEATURES])\n",
    "\n",
    "print(\"Data Scaling Complete for Train, Validation, and Test sets.\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 2.2: Save the Scaler\n",
    "# ----------------------------------------------------------------------\n",
    "# 3. Save the Scaler object using joblib\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "print(f\"2. Scaler saved successfully to: {SCALER_PATH}\")\n",
    "\n",
    "\n",
    "# Verification (Show the transformation effect)\n",
    "print(\"\\nVerification of Scaled Data (X_train head):\")\n",
    "print(X_train_scaled[SCALING_FEATURES].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-tobOaGsAyq"
   },
   "source": [
    "baselien model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4509,
     "status": "ok",
     "timestamp": 1765522740651,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "c4bBItFSsOrs",
    "outputId": "ca6adc4f-6a94-49cd-d858-1d68145d2b6d"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "os.makedirs('models', exist_ok=True)\n",
    "MODEL_PATH = 'models/logreg_baseline.joblib'\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 3.1: Train Logistic Regression Baseline\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "print(\"--- Phase 3.1: Training Logistic Regression Baseline Model ---\")\n",
    "\n",
    "# 1. Initialize Logistic Regression Model\n",
    "# key parameters:\n",
    "# - class_weight='balanced': Crucial for imbalance. It automatically adjusts weights inversely proportional\n",
    "#   to class frequencies, giving more importance to the rare 'Fraud' class (Class 1).\n",
    "# - solver='liblinear': A good choice for small datasets or when using L1/L2 regularization (default for this model).\n",
    "# - max_iter: Increased for convergence on a large dataset.\n",
    "logreg_model = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear',\n",
    "    random_state=42,\n",
    "    max_iter=1000  # Ensure the model converges\n",
    ")\n",
    "\n",
    "# 2. Train the model using the scaled features from Phase 2\n",
    "print(\"Starting model training on X_train_scaled...\")\n",
    "logreg_model.fit(X_train_scaled, y_train)\n",
    "print(\"Logistic Regression model trained successfully.\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 3.4 (Pre-emptive): Save the LogReg model\n",
    "# ----------------------------------------------------------------------\n",
    "joblib.dump(logreg_model, MODEL_PATH)\n",
    "print(f\"\\nModel saved successfully to: {MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 790
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1765522746319,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "HDO6lTzusurO",
    "outputId": "fbb11319-7f19-4e70-ab3f-08a971cf853d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "# Assume logreg_model is the trained model from the previous step.\n",
    "# Assume X_val_scaled and y_val are the scaled validation features/labels.\n",
    "# Feature names are taken from the scaled validation set columns.\n",
    "FEATURE_NAMES = X_val_scaled.columns\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 3.2: Evaluate Performance on the Validation Set\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"--- Phase 3.2: Evaluating Logistic Regression on Validation Set ---\")\n",
    "\n",
    "# 1. Predict Probabilities (necessary for AUPRC)\n",
    "y_scores = logreg_model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "# 2. Calculate AUPRC (Primary Metric)\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, y_scores)\n",
    "auprc = auc(recall, precision)\n",
    "\n",
    "# 3. Calculate F1-Score and Confusion Matrix (requires binary predictions)\n",
    "# We use the default classification threshold of 0.5 for the initial F1/CM\n",
    "y_pred = (y_scores >= 0.5).astype(int)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "\n",
    "print(f\"\\n--- Baseline Model Validation Metrics ---\")\n",
    "print(f\"AUPRC (Precision-Recall AUC): {auprc:.4f} (Primary Metric)\")\n",
    "print(f\"F1-Score (using 0.5 threshold): {f1:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Display the Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('LogReg Confusion Matrix (Validation Set)')\n",
    "plt.show()\n",
    "\n",
    "# Extract Recall and Precision from the CM for discussion:\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "recall = TP / (TP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "print(f\"\\nModel Performance Insights:\")\n",
    "print(f\"True Positives (TP - Correctly Flagged Fraud): {TP}\")\n",
    "print(f\"False Negatives (FN - Missed Fraud): {FN}\")\n",
    "print(f\"Recall (Fraud Captured): {recall:.2%}\")\n",
    "print(f\"Precision (Flagged Correctly): {precision:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTzH2Biowf1A"
   },
   "source": [
    "##adv model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y4GRtL_4whPV"
   },
   "outputs": [],
   "source": [
    "!pip install optuna\n",
    "!pip install lightgbm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Ensure 'models' directory exists for saving\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 4.1: Calculate scale_pos_weight for Imbalance Handling\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Total Negatives (Non-Fraud)\n",
    "neg_count = y_train.value_counts()[0]\n",
    "# Total Positives (Fraud)\n",
    "pos_count = y_train.value_counts()[1]\n",
    "\n",
    "# Calculate the imbalance handling parameter\n",
    "SCALE_POS_WEIGHT = neg_count / pos_count\n",
    "print(f\"Total Non-Fraud (0): {neg_count}\")\n",
    "print(f\"Total Fraud (1): {pos_count}\")\n",
    "print(f\"Calculated scale_pos_weight: {SCALE_POS_WEIGHT:.2f}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 4.2: Hyperparameter Tuning with Optuna (Optimize AUPRC)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Defines the Optuna objective function to minimize/maximize the metric.\"\"\"\n",
    "\n",
    "    # 1. Hyperparameter Search Space\n",
    "    lgbm_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc', # Use AUC for LightGBM's internal metric during training\n",
    "        'boosting_type': 'gbdt',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 0.1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 0.9),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 0.9),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-4, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-4, 1.0),\n",
    "        'scale_pos_weight': SCALE_POS_WEIGHT, # Use the calculated imbalance ratio\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    # 2. Train the Model with early stopping on the Validation set\n",
    "    model = lgb.LGBMClassifier(**lgbm_params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        eval_set=[(X_val_scaled, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(100, verbose=False)] # Stop after 100 rounds with no improvement\n",
    "    )\n",
    "\n",
    "    # 3. Evaluate Model on Validation Set and Return AUPRC\n",
    "    # AUPRC is the true optimization metric, calculated manually on validation predictions\n",
    "    y_scores = model.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_val, y_scores)\n",
    "    auprc = auc(recall, precision)\n",
    "\n",
    "    return auprc\n",
    "\n",
    "# 4. Run the Optuna Study\n",
    "print(\"\\n--- Starting Optuna Hyperparameter Search (Target: Maximize AUPRC) ---\")\n",
    "study = optuna.create_study(direction='maximize', study_name='lgbm_auprc_tuning')\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Note: n_trials=50 is for quick example; use 500+ for a production quality result\n",
    "\n",
    "print(\"\\n--- Optuna Study Finished ---\")\n",
    "print(f\"Best AUPRC found on Validation Set: {study.best_value:.4f}\")\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(study.best_params)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Phase 4.3: Train Final LightGBM Model with Best Params & Save\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# 1. Retrieve best parameters and train final model on full training set\n",
    "best_params = study.best_params\n",
    "final_lgbm_params = {\n",
    "    **best_params,\n",
    "    'objective': 'binary',\n",
    "    'scale_pos_weight': SCALE_POS_WEIGHT,\n",
    "    'n_jobs': -1,\n",
    "    'seed': 42,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "final_lgbm_model = lgb.LGBMClassifier(**final_lgbm_params)\n",
    "\n",
    "# Train without early stopping on the validation set for final model,\n",
    "# using the best n_estimators found (or a fixed high number)\n",
    "# We will use the best n_estimators found during the tuning\n",
    "print(\"\\nTraining final LightGBM model with best parameters...\")\n",
    "final_lgbm_model.fit(X_train_scaled, y_train)\n",
    "print(\"Final LightGBM model trained successfully.\")\n",
    "\n",
    "\n",
    "# 2. Save the final model\n",
    "LGBM_MODEL_PATH = 'models/lgbm_advanced_model.joblib'\n",
    "joblib.dump(final_lgbm_model, LGBM_MODEL_PATH)\n",
    "print(f\"Final LightGBM model saved to: {LGBM_MODEL_PATH}\")\n",
    "\n",
    "# The final model 'final_lgbm_model' is ready for Phase 4.3 (Final Evaluation on Test Set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6929,
     "status": "ok",
     "timestamp": 1765464618092,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "oWFjnn5uzEGW"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc, recall_score, precision_score\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Setup: Define file paths\n",
    "# ----------------------------------------------------------------------\n",
    "LOGREG_MODEL_PATH = 'models/logreg_baseline.joblib'\n",
    "LGBM_MODEL_PATH = 'models/lgbm_advanced_model.joblib'\n",
    "\n",
    "# Assume X_test_scaled and y_test are available from Phase 2/1.\n",
    "print(\"--- Phase 4.3: Final Evaluation and Comparison on Test Set ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Load the trained models\n",
    "    logreg_model = joblib.load(LOGREG_MODEL_PATH)\n",
    "    lgbm_model = joblib.load(LGBM_MODEL_PATH)\n",
    "    print(\"Models loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not load one or more models. Ensure files exist in 'models/' directory. {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2. Define Metric Calculation Helper Function\n",
    "# -----------------------------------------------\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, threshold=0.5):\n",
    "    \"\"\"Calculates AUPRC, Recall, and Precision on the test set.\"\"\"\n",
    "\n",
    "    # Get probabilities for AUPRC\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # AUPRC (Precision-Recall AUC)\n",
    "    precision_val, recall_val, _ = precision_recall_curve(y_test, y_scores)\n",
    "    auprc = auc(recall_val, precision_val)\n",
    "\n",
    "    # Binary predictions for Recall and Precision at the specified threshold\n",
    "    y_pred = (y_scores >= threshold).astype(int)\n",
    "\n",
    "    # Recall and Precision\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "\n",
    "    return auprc, recall, precision\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# 3. Run Evaluation for Both Models\n",
    "# ---------------------------------------\n",
    "\n",
    "# Evaluate Logistic Regression Baseline\n",
    "logreg_auprc, logreg_recall, logreg_precision = evaluate_model(logreg_model, X_test_scaled, y_test)\n",
    "\n",
    "# Evaluate LightGBM Advanced Model\n",
    "lgbm_auprc, lgbm_recall, lgbm_precision = evaluate_model(lgbm_model, X_test_scaled, y_test)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Generate Comparison Table\n",
    "# -------------------------------\n",
    "\n",
    "comparison_data = [\n",
    "    [\"Logistic Regression (Baseline)\", logreg_auprc, logreg_recall, logreg_precision],\n",
    "    [\"LightGBM (Advanced)\", lgbm_auprc, lgbm_recall, lgbm_precision]\n",
    "]\n",
    "\n",
    "headers = [\"Model\", \"AUPRC (Primary)\", \"Recall (at 0.5)\", \"Precision (at 0.5)\"]\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison on UNSEEN Test Set (Threshold=0.5) ---\")\n",
    "print(tabulate(comparison_data, headers=headers, floatfmt=(\".0f\", \".4f\", \".4f\", \".4f\"), tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# ------------------\n",
    "# Interpretation\n",
    "# ------------------\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if lgbm_auprc > logreg_auprc:\n",
    "    print(f\"✅ Conclusion: The LightGBM model significantly outperformed the Logistic Regression baseline in AUPRC ({lgbm_auprc:.4f} vs {logreg_auprc:.4f}).\")\n",
    "    print(\"This indicates better overall discrimination between fraud and non-fraud events.\")\n",
    "    # Optional: Check if LightGBM improved the Precision/Recall balance\n",
    "    if lgbm_recall > logreg_recall and lgbm_precision > logreg_precision:\n",
    "        print(\"LightGBM also improved both Recall and Precision simultaneously at the 0.5 threshold.\")\n",
    "    elif lgbm_recall > logreg_recall:\n",
    "        print(\"LightGBM prioritized Recall, which is often desirable in fraud detection.\")\n",
    "    else:\n",
    "        print(\"LightGBM prioritized Precision, which is often desirable for minimizing false alarms.\")\n",
    "        ##these are poor numbers for business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AruPjNCt1tT6"
   },
   "source": [
    "## threshold tuning for business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6319,
     "status": "ok",
     "timestamp": 1765464630097,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "Ovf6CCCZ02rv"
   },
   "outputs": [],
   "source": [
    "#Define file paths and target precision\n",
    "LGBM_MODEL_PATH = 'models/lgbm_advanced_model.joblib'\n",
    "THRESHOLD_PATH = 'models/production_threshold.joblib'\n",
    "TARGET_PRECISION = 0.80\n",
    "\n",
    "# Load model and predict scores\n",
    "final_lgbm_model = joblib.load(LGBM_MODEL_PATH)\n",
    "y_scores = final_lgbm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate PR curve arrays and find the threshold\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "thresholds = np.append(thresholds, 1.0) # Align array sizes\n",
    "\n",
    "# Find the index of the highest threshold that meets or exceeds TARGET_PRECISION\n",
    "index_for_target = np.argmax(precision >= TARGET_PRECISION)\n",
    "\n",
    "# Extract and save the optimal threshold\n",
    "optimal_threshold = thresholds[index_for_target]\n",
    "final_precision = precision[index_for_target]\n",
    "final_recall = recall[index_for_target]\n",
    "joblib.dump(optimal_threshold, THRESHOLD_PATH)\n",
    "\n",
    "# Output final result\n",
    "print(f\"Optimal Threshold (Precision >= {TARGET_PRECISION:.0%}): {optimal_threshold:.4f}\")\n",
    "print(f\"Resulting Precision: {final_precision:.4f} | Recall: {final_recall:.4f}\")\n",
    "print(f\"Threshold saved to: {THRESHOLD_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ml-NeYHW75hR"
   },
   "source": [
    "##SHAP PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "executionInfo": {
     "elapsed": 38269,
     "status": "error",
     "timestamp": 1765465415082,
     "user": {
      "displayName": "vibhas jadhav",
      "userId": "02593397558789285157"
     },
     "user_tz": -330
    },
    "id": "YBZcmojq777j"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# --- Assumptions ---\n",
    "# We assume 'final_lgbm_model' and 'X_test_scaled' are loaded/available.\n",
    "\n",
    "# 1. Initialize SHAP Explainer\n",
    "explainer = shap.TreeExplainer(final_lgbm_model)\n",
    "\n",
    "# Use a sample of the test data for faster computation\n",
    "# ENSURE X_test_scaled is available and has many rows\n",
    "X_sample = X_test_scaled.sample(n=5000, random_state=42)\n",
    "\n",
    "# 2. Calculate SHAP values\n",
    "# For binary classification, this returns a LIST of two matrices: [Class 0, Class 1]\n",
    "raw_shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "# 3. CRITICAL DIMENSIONALITY CHECK AND EXTRACTION\n",
    "if isinstance(raw_shap_values, list) and len(raw_shap_values) > 1:\n",
    "    # Extract the matrix for the positive class (Fraud), which is index [1]\n",
    "    shap_values_matrix = raw_shap_values[1]\n",
    "    print(\"Detected list of SHAP matrices. Extracted positive class matrix (index 1).\")\n",
    "else:\n",
    "    # If not a list of two, assume it's the single matrix output\n",
    "    shap_values_matrix = raw_shap_values\n",
    "    print(\"Detected single SHAP matrix (or unexpected format). Using it directly.\")\n",
    "\n",
    "# Ensure the matrix is 2D by squeezing any extra dimensions (e.g., (5000, 30, 1) -> (5000, 30))\n",
    "shap_values_matrix = np.squeeze(shap_values_matrix)\n",
    "\n",
    "# Final check for the summary plot requirement: must be a matrix (ndim=2)\n",
    "if shap_values_matrix.ndim != 2:\n",
    "    # This should now catch any remaining dimensionality issues\n",
    "    raise AssertionError(\n",
    "        f\"SHAP summary plot requires a matrix (2D array). Final shape is {shap_values_matrix.shape}. \"\n",
    "        \"Please ensure X_sample has multiple rows (e.g., 5000).\"\n",
    "    )\n",
    "\n",
    "print(f\"SHAP Matrix ready for plotting with shape: {shap_values_matrix.shape}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# A. Global Summary Plot (How features influence the model overall)\n",
    "# ----------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(\n",
    "    shap_values_matrix,\n",
    "    X_sample,\n",
    "    plot_type=\"dot\",\n",
    "    class_names=['Non-Fraud', 'Fraud'],\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Global Feature Importance (Impact on Fraud Probability)\")\n",
    "plt.savefig(\"shap_global_summary_plot.png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"SHAP Global Summary Plot generated successfully: shap_global_summary_plot.png\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# B. Local Force Plot Data Generation (For notebook rendering)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Select a high-probability fraud transaction\n",
    "y_scores = final_lgbm_model.predict_proba(X_sample)[:, 1]\n",
    "high_risk_index_in_sample = np.argmax(y_scores)\n",
    "high_risk_index = X_sample.iloc[high_risk_index_in_sample].name\n",
    "\n",
    "single_instance = X_sample.loc[[high_risk_index]]\n",
    "\n",
    "raw_single_shap_values = explainer.shap_values(single_instance)\n",
    "\n",
    "# Extract the vector for the positive class and the base value\n",
    "if isinstance(raw_single_shap_values, list) and len(raw_single_shap_values) > 1:\n",
    "    single_shap_values_vector = raw_single_shap_values[1]\n",
    "    expected_value = explainer.expected_value[1]\n",
    "else:\n",
    "    single_shap_values_vector = raw_single_shap_values\n",
    "    expected_value = explainer.expected_value\n",
    "\n",
    "# Save the necessary components\n",
    "force_plot_data = {\n",
    "    'shap_values': np.squeeze(single_shap_values_vector),\n",
    "    'expected_value': expected_value,\n",
    "    'instance': single_instance\n",
    "}\n",
    "joblib.dump(force_plot_data, \"shap_local_force_plot_data.joblib\")\n",
    "print(f\"SHAP Local Force Plot data saved to shap_local_force_plot_data.joblib (Transaction Index: {high_risk_index}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time_bin'] = pd.qcut(df['Time'], q=50, duplicates='drop')  \n",
    "fraud_rate = df.groupby('time_bin')['Class'].mean()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(fraud_rate.values)\n",
    "plt.title(\"Fraud Rate across Time\")\n",
    "plt.xlabel(\"Time bins\")\n",
    "plt.ylabel(\"Fraud Rate\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPsPLNp6QXU5xUFoaT+Assc",
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26dfb678add44ba596d2741a34cf0e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7eb1a88e880d4c71bc9248bbc17bb5a1",
      "placeholder": "​",
      "style": "IPY_MODEL_ad6659e798e04dad94782af1b22f9120",
      "value": " 50/50 [09:57&lt;00:00, 10.80s/it]"
     }
    },
    "65ecdd04801e4939bded25e7354aae66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "74e5ff6db97f4da99cd5bb00b3f6279b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eb1a88e880d4c71bc9248bbc17bb5a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8822622bb6f041dc95c08e00742bb522": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe610c686932433ab97f5bd70df5959c",
       "IPY_MODEL_b014565385ba415aac103d3d392f1d30",
       "IPY_MODEL_26dfb678add44ba596d2741a34cf0e3c"
      ],
      "layout": "IPY_MODEL_74e5ff6db97f4da99cd5bb00b3f6279b"
     }
    },
    "ad6659e798e04dad94782af1b22f9120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b014565385ba415aac103d3d392f1d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e92fc9d7b0c741c4a2d0089537537738",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65ecdd04801e4939bded25e7354aae66",
      "value": 50
     }
    },
    "c124388666104561b38e48c73ce82c63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e92fc9d7b0c741c4a2d0089537537738": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe610c686932433ab97f5bd70df5959c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff38de67da764f0a808a154ff789dc14",
      "placeholder": "​",
      "style": "IPY_MODEL_c124388666104561b38e48c73ce82c63",
      "value": "Best trial: 33. Best value: 0.822853: 100%"
     }
    },
    "ff38de67da764f0a808a154ff789dc14": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
